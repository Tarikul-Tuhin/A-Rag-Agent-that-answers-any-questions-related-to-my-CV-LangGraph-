ğŸ“„ Project Tagline
â€œI Fed My CV to an LLM â€” and It Answered Questions About Me!â€

ğŸ’¡ Project Description
  - This project demonstrates how to build a Retrieval-Augmented Generation (RAG) Agent using LangGraph.
The RAG agent can read and understand your PDF documents â€” in this case, my CV â€” and answer questions related to its content.

  - You can also feed any PDF into this system and query it using just a few lines of code provided in this repository.

ğŸ–¼ï¸ Images (Outputs):


ğŸ§© Steps that I followed to make this RAG Agent
  - Load my LLM
  - Load my CV.pdf (A_Flutter_Developer_cv_Tarikul_Islam.pdf) using pypdfloader
  - Split my CV in different chunks to reduce token size
  - Embedded the splitted chunks for vector representation (Using GoogleGenerativeAIEmbeddings)
  - Store the Embedded part into Chroma Database
  - Retrieve the relevent context from the Chroma Database when user asks any question and LLM answers the relevant context

ğŸ§  Tech Stack
  - LangGraph â€“ For workflow orchestration
  - Gemini (Google Generative AI) â€“ As the LLM
  - PyPDFLoader â€“ To load and extract text from PDFs
  - ChromaDB â€“ For vector storage and retrieval
  - GoogleGenerativeAIEmbeddings â€“ To create text embeddings